name: SuperArgo Scraping Diario

on:
  schedule:
    # 2:00 AM Bogotá (UTC-5) es 7:00 AM UTC
    - cron: '0 7 * * *'
  workflow_dispatch: # Permite ejecución manual para pruebas

jobs:
  scraping_job:
    runs-on: ubuntu-latest
    
    # Permisos necesarios para leer el repositorio
    permissions:
      contents: read

    steps:
    - name: Checkout del código
      uses: actions/checkout@v4

    - name: Configurar Python 3.10
      uses: actions/setup-python@v4
      with:
        python-version: '3.10'

    - name: Instalar dependencias
      run: |
        python -m pip install --upgrade pip
        pip install selenium pandas openpyxl

    - name: Ejecutar Script de Scraping
      env:
        # Variables vinculadas a tus GitHub Secrets
        PQRD_USER: ${{ secrets.PQRD_USER }}
        PQRD_PASS: ${{ secrets.PQRD_PASS }}
      # Ejecuta el archivo con el nombre exacto que indicaste
      run: python Web_Scraping.py

    - name: Guardar Resultados y Capturas de Error
      if: always() # Se ejecuta aunque el script de arriba falle
      uses: actions/upload-artifact@v4
      with:
        name: Entregables_Scraping
        path: |
          Reclamos_scraping.xlsx
          debug_error.png
        retention-days: 5
